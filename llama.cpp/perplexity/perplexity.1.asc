[4mLLAMAFILE-PERPLEXITY[24m(1)     General Commands Manual    [4mLLAMAFILE-PERPLEXITY[24m(1)

[1mNAME[0m
       llamafile-perplexity ‚Äî LLM benchmarking tool

[1mSYNOPSIS[0m
       [1mllamafile-perplexity [22m[flags...]

[1mDESCRIPTION[0m
       Perplexity  is  one  of the most common metrics for evaluating language
       models. The [1mllamafile-perplexity [22mprogram can be used to gauge the qual‚Äê
       ity of an LLM implementation. It is defined as the exponentiated  aver‚Äê
       age  negative  log-likelihood  of  a sequence, calculated with exponent
       base e. Lower perplexity scores are better.

[1mOPTIONS[0m
       The following options are available:

       [1m-h[22m, [1m--help[0m
               Show help message and exit.

       [1m-m [4m[22mFNAME[24m, [1m--model [4m[22mFNAME[0m
               Model path (default: models/7B/ggml-model-f16.gguf)

       [1m-f [4m[22mFNAME[24m, [1m--file [4m[22mFNAME[0m
               Raw data input file.

       [1m--chunks [4m[22mN[0m
               Max number of chunks to process.

               [1m-   [22m-1 = all

               Default: -1

       [1m-t [4m[22mN[24m, [1m--threads [4m[22mN[0m
               Number of threads to use during generation (default: nproc/2)

       [1m-s [4m[22mSEED[24m, [1m--seed [4m[22mSEED[0m
               Random Number Generator (RNG) seed  (default:  -1,  use  random
               seed for < 0)

       [1m--hellaswag[0m
               Compute  HellaSwag  score  over random tasks from datafile sup‚Äê
               plied with -f

       [1m--hellaswag-tasks [4m[22mN[0m
               Number of tasks to use when computing the HellaSwag score.

               Default: 400

       [1m--winogrande[0m
               Compute Winogrande score over random tasks from  datafile  sup‚Äê
               plied by the [1m-f [22mflag.

       [1m--winogrande-tasks [4m[22mN[0m
               Number of tasks to use when computing the Winogrande score.

               Default: 0

[1mEXAMPLE[0m
       One dataset commonly used in the llama.cpp community for measuring per‚Äê
       plexity  is  wikitext-2-raw.  To use it when testing how well both your
       model and llamafile are performing you could run the following:

       wget https://cosmo.zip/pub/datasets/wikitext-2-raw/wiki.test.raw
       llamafile-perplexity -m model.gguf -f wiki.test.raw -s 31337

       This can sometimes lead to surprising conclusions, like how Q5 weights
       might be better for a particular model than Q6.

[1mSEE ALSO[0m
       [4mllamafile[24m(1)

Llamafile Manual               December 5, 2023        [4mLLAMAFILE-PERPLEXITY[24m(1)
